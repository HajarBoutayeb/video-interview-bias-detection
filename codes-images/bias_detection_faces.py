import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler
from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, 
                           classification_report, confusion_matrix, roc_auc_score, roc_curve)
from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.combine import SMOTETomek, SMOTEENN
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

# ================= CHEMINS =================
EXCEL_PATH = r"C:\Users\ADmiN\Desktop\video_project\annotations\faces_annotations.xlsx"

# ================= CONFIGURATION AM√âLIOR√âE =================
plt.style.use('seaborn-v0_8')
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10

# Strat√©gies d'√©chantillonnage pour donn√©es d√©s√©quilibr√©es
SAMPLING_STRATEGIES = {
    'SMOTE': SMOTE(random_state=42),
    'ADASYN': ADASYN(random_state=42),
    'BorderlineSMOTE': BorderlineSMOTE(random_state=42),
    'SMOTETomek': SMOTETomek(random_state=42),
    'SMOTEENN': SMOTEENN(random_state=42)
}

# Classificateurs am√©lior√©s avec meilleurs param√®tres
ENHANCED_CLASSIFIERS = {
    "RandomForest": RandomForestClassifier(
        n_estimators=200, 
        max_depth=10,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42,
        n_jobs=-1
    ),
    "GradientBoosting": GradientBoostingClassifier(
        n_estimators=200,
        learning_rate=0.1,
        max_depth=6,
        random_state=42
    ),
    "AdaBoost": AdaBoostClassifier(
        n_estimators=100,
        learning_rate=1.0,
        random_state=42
    ),
    "SVM": SVC(
        probability=True, 
        random_state=42,
        kernel='rbf',
        C=1.0
    ),
    "LogisticRegression": LogisticRegression(
        random_state=42,
        max_iter=1000,
        multi_class='ovr'
    ),
    "MLP": MLPClassifier(
        hidden_layer_sizes=(100, 50),
        max_iter=500,
        random_state=42,
        early_stopping=True
    ),
    "NaiveBayes": GaussianNB()
}

# ================= CHARGER ET PR√âPARER LES DONN√âES =================
print("üîÑ Chargement des donn√©es...")
df = pd.read_excel(EXCEL_PATH)
print(f"üìä Taille initiale des donn√©es : {df.shape}")

# ================= CR√âER CAT√âGORIE D'√ÇGE =================
def get_age_category(age):
    if pd.isna(age):
        return "Unknown"
    if age < 13: return "Child"
    elif age < 20: return "Teen"
    elif age < 30: return "Young Adult"
    elif age < 45: return "Adult"
    elif age < 65: return "Middle-aged"
    else: return "Senior"

df['age_category'] = df['age'].apply(get_age_category)

# ================= PR√âTRAITEMENT DES DONN√âES =================
def clean_numeric_columns(df, columns):
    """Nettoyer et convertir les colonnes en num√©riques"""
    cleaned_df = df.copy()
    
    for col in columns:
        if col in cleaned_df.columns:
            # Convertir en string d'abord, puis nettoyer
            cleaned_df[col] = cleaned_df[col].astype(str)
            # Remplacer les virgules par des points et supprimer les points finaux
            cleaned_df[col] = cleaned_df[col].str.replace(',', '.', regex=False).str.rstrip('.')
            # Remplacer 'nan', 'None', cha√Ænes vides avec NaN
            cleaned_df[col] = cleaned_df[col].replace(['nan', 'None', '', 'null'], np.nan)
            # Convertir en num√©rique
            cleaned_df[col] = pd.to_numeric(cleaned_df[col], errors='coerce')
            # Remplir NaN avec 0 pour les colonnes de confiance
            if 'confidence' in col:
                cleaned_df[col] = cleaned_df[col].fillna(0.0)
            else:
                cleaned_df[col] = cleaned_df[col].fillna(cleaned_df[col].median())
    
    return cleaned_df

# ================= ING√âNIERIE DE CARACT√âRISTIQUES AM√âLIOR√âE =================
def create_enhanced_features(df):
    """Cr√©er des caract√©ristiques suppl√©mentaires pour une meilleure pr√©diction"""
    print("üîß Cr√©ation de caract√©ristiques am√©lior√©es...")
    
    # D'abord, nettoyer toutes les colonnes num√©riques
    numeric_columns = ['age', 'gender_confidence', 'race_confidence', 'emotion_confidence', 
                      'bbox_w', 'bbox_h', 'bbox_x', 'bbox_y', 'face_area']
    
    enhanced_df = clean_numeric_columns(df, numeric_columns)
    
    # S'assurer d'avoir les colonnes requises pour les calculs
    required_cols = ['gender_confidence', 'race_confidence', 'emotion_confidence', 'age']
    for col in required_cols:
        if col not in enhanced_df.columns:
            enhanced_df[col] = 0.0
        # S'assurer qu'elles sont num√©riques
        enhanced_df[col] = pd.to_numeric(enhanced_df[col], errors='coerce').fillna(0.0)
    
    try:
        # Ratios et combinaisons de confiance (avec division s√©curis√©e)
        enhanced_df['conf_ratio_gender_race'] = enhanced_df['gender_confidence'] / (enhanced_df['race_confidence'] + 0.001)
        enhanced_df['conf_ratio_emotion_gender'] = enhanced_df['emotion_confidence'] / (enhanced_df['gender_confidence'] + 0.001)
        enhanced_df['conf_product'] = enhanced_df['gender_confidence'] * enhanced_df['race_confidence'] * enhanced_df['emotion_confidence']
        
        # G√©rer les valeurs infinies
        enhanced_df['conf_ratio_gender_race'] = enhanced_df['conf_ratio_gender_race'].replace([np.inf, -np.inf], 0)
        enhanced_df['conf_ratio_emotion_gender'] = enhanced_df['conf_ratio_emotion_gender'].replace([np.inf, -np.inf], 0)
        
        print("‚úÖ Ratios de confiance cr√©√©s avec succ√®s")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors de la cr√©ation des ratios de confiance : {e}")
        enhanced_df['conf_ratio_gender_race'] = 0.0
        enhanced_df['conf_ratio_emotion_gender'] = 0.0
        enhanced_df['conf_product'] = 0.0
    
    try:
        # Caract√©ristiques g√©om√©triques du visage
        if 'bbox_w' in enhanced_df.columns and 'bbox_h' in enhanced_df.columns:
            enhanced_df['bbox_w'] = pd.to_numeric(enhanced_df['bbox_w'], errors='coerce').fillna(100)
            enhanced_df['bbox_h'] = pd.to_numeric(enhanced_df['bbox_h'], errors='coerce').fillna(100)
            
            enhanced_df['face_aspect_ratio'] = enhanced_df['bbox_w'] / (enhanced_df['bbox_h'] + 1)
            enhanced_df['face_area_norm'] = enhanced_df['bbox_w'] * enhanced_df['bbox_h']
            
            print("‚úÖ Caract√©ristiques g√©om√©triques cr√©√©es avec succ√®s")
        else:
            enhanced_df['face_aspect_ratio'] = 1.0
            enhanced_df['face_area_norm'] = 10000.0
            print("‚ö†Ô∏è Colonnes bbox introuvables, utilisation de valeurs par d√©faut")
            
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors de la cr√©ation des caract√©ristiques g√©om√©triques : {e}")
        enhanced_df['face_aspect_ratio'] = 1.0
        enhanced_df['face_area_norm'] = 10000.0
    
    try:
        # Caract√©ristiques bas√©es sur l'√¢ge
        enhanced_df['age'] = pd.to_numeric(enhanced_df['age'], errors='coerce').fillna(25.0)
        enhanced_df['is_young'] = (enhanced_df['age'] < 25).astype(int)
        enhanced_df['is_senior'] = (enhanced_df['age'] > 60).astype(int)
        enhanced_df['age_squared'] = enhanced_df['age'] ** 2
        
        print("‚úÖ Caract√©ristiques bas√©es sur l'√¢ge cr√©√©es avec succ√®s")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors de la cr√©ation des caract√©ristiques d'√¢ge : {e}")
        enhanced_df['is_young'] = 0
        enhanced_df['is_senior'] = 0
        enhanced_df['age_squared'] = 625.0
    
    print(f"üìä Caract√©ristiques am√©lior√©es cr√©√©es. Nouvelle forme : {enhanced_df.shape}")
    
    return enhanced_df

# ================= FOCUS SUR RACE ET √âMOTION =================
target_labels = ['race', 'emotion']

# Caract√©ristiques am√©lior√©es
base_features = ['age', 'gender_confidence', 'race_confidence', 'emotion_confidence']
enhanced_features = [
    'conf_ratio_gender_race', 'conf_ratio_emotion_gender', 'conf_product',
    'is_young', 'is_senior', 'age_squared'
]

# Ajouter les caract√©ristiques g√©om√©triques si disponibles
geometry_features = []
if 'bbox_w' in df.columns:
    geometry_features = ['face_aspect_ratio', 'face_area_norm']
    enhanced_features.extend(geometry_features)

all_features = base_features + enhanced_features

df = create_enhanced_features(df)

# V√©rifier quelles colonnes nous avons apr√®s la cr√©ation de caract√©ristiques
print("üìã Colonnes disponibles apr√®s l'ing√©nierie de caract√©ristiques :")
available_columns = df.columns.tolist()
for i, col in enumerate(available_columns):
    print(f"   {i+1:2d}. {col}")

# D√©finir les caract√©ristiques de base
base_features = ['age', 'gender_confidence', 'race_confidence', 'emotion_confidence', 'avg_confidence']

# Caract√©ristiques am√©lior√©es (inclure uniquement celles qui existent)
enhanced_features = [
    'conf_ratio_gender_race', 'conf_ratio_emotion_gender', 'conf_product',
    'is_young', 'is_senior', 'age_squared'
]

# Ajouter les caract√©ristiques g√©om√©triques si elles existent
geometry_features = []
if 'face_aspect_ratio' in df.columns:
    geometry_features = ['face_aspect_ratio', 'face_area_norm']
    enhanced_features.extend(geometry_features)

# V√©rifier quelles caract√©ristiques de base sont disponibles
available_base_features = []
for feature in base_features:
    if feature in df.columns:
        available_base_features.append(feature)
    else:
        print(f"‚ö†Ô∏è Caract√©ristique de base introuvable : {feature}")

# V√©rifier quelles caract√©ristiques am√©lior√©es sont disponibles
available_enhanced_features = []
for feature in enhanced_features:
    if feature in df.columns:
        available_enhanced_features.append(feature)
    else:
        print(f"‚ö†Ô∏è Caract√©ristique am√©lior√©e introuvable : {feature}")

all_features = available_base_features + available_enhanced_features
print(f"‚úÖ Total des caract√©ristiques disponibles : {len(all_features)} caract√©ristiques")
print(f"üìä Caract√©ristiques de base : {available_base_features}")
print(f"üîß Caract√©ristiques am√©lior√©es : {available_enhanced_features}")


# ================= NETTOYAGE DES DONN√âES ET PR√âPARATION DES CARACT√âRISTIQUES =================
# Supprimer les lignes avec des √©tiquettes cibles manquantes
print("üßπ Nettoyage des donn√©es...")
for label in target_labels:
    initial_count = len(df)
    df = df.dropna(subset=[label])
    removed = initial_count - len(df)
    if removed > 0:
        print(f"üßπ Supprim√© {removed} lignes avec {label} manquant")

# Caract√©ristiques am√©lior√©es (seront nettoy√©es dans la fonction)
all_features = base_features + enhanced_features

# ================= PR√âPARATION FINALE DES DONN√âES =================
print("üîÑ Traitement des caract√©ristiques...")

# Obtenir uniquement les caract√©ristiques qui existent dans le dataframe
available_features = [f for f in all_features if f in df.columns]
if len(available_features) < len(all_features):
    missing_features = set(all_features) - set(available_features)
    print(f"‚ö†Ô∏è Caract√©ristiques manquantes : {missing_features}")
    print(f"üìä Utilisation de {len(available_features)} caract√©ristiques disponibles")

# Cr√©er une matrice de caract√©ristiques avec un nettoyage robuste
X = df[available_features].copy()

# Nettoyer toutes les caract√©ristiques syst√©matiquement
for col in X.columns:
    if X[col].dtype == 'object':
        X[col] = X[col].astype(str).str.replace(',', '.', regex=False).str.rstrip('.')
        X[col] = X[col].replace(['nan', 'None', '', 'null'], np.nan)
    
    X[col] = pd.to_numeric(X[col], errors='coerce')

# Remplir les valeurs manquantes avec la m√©diane pour chaque colonne
X = X.fillna(X.median())

# G√©rer tout probl√®me restant
X = X.replace([np.inf, -np.inf], 0)

print(f"üìä Forme finale de la matrice de caract√©ristiques : {X.shape}")
print(f"üéØ Caract√©ristiques utilis√©es : {list(X.columns)}")
print(f"‚úÖ Pr√©traitement des donn√©es termin√© avec succ√®s")

# ================= FONCTION D'√âVALUATION AVANC√âE =================
def advanced_evaluate_classifier(X_train, X_test, y_train, y_test, clf, label_name):
    """√âvaluation am√©lior√©e avec plusieurs m√©triques"""
    
    # Entra√Æner le classificateur
    clf.fit(X_train, y_train)
    
    # Pr√©dictions
    y_pred = clf.predict(X_test)
    y_pred_proba = None
    
    try:
        y_pred_proba = clf.predict_proba(X_test)
    except:
        pass
    
    # Calculer les m√©triques
    metrics = {
        "accuracy": accuracy_score(y_test, y_pred),
        "precision": precision_score(y_test, y_pred, average='weighted', zero_division=0),
        "recall": recall_score(y_test, y_pred, average='weighted', zero_division=0),
        "f1": f1_score(y_test, y_pred, average='weighted', zero_division=0),
        "f1_macro": f1_score(y_test, y_pred, average='macro', zero_division=0),
        "f1_micro": f1_score(y_test, y_pred, average='micro', zero_division=0)
    }
    
    # ROC AUC pour multi-classes
    if y_pred_proba is not None and len(np.unique(y_test)) > 2:
        try:
            metrics["roc_auc"] = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='weighted')
        except:
            metrics["roc_auc"] = 0
    elif y_pred_proba is not None and len(np.unique(y_test)) == 2:
        try:
            metrics["roc_auc"] = roc_auc_score(y_test, y_pred_proba[:, 1])
        except:
            metrics["roc_auc"] = 0
    else:
        metrics["roc_auc"] = 0
    
    return metrics, y_pred, y_pred_proba

# ================= FONCTIONS DE VISUALISATION =================
def plot_class_distribution(y, title, label_encoder=None):
    """Tracer la distribution des classes"""
    plt.figure(figsize=(12, 6))
    
    if label_encoder:
        labels = label_encoder.inverse_transform(range(len(label_encoder.classes_)))
        counts = pd.Series(y).value_counts().sort_index()
        plt.bar(range(len(labels)), [counts.get(i, 0) for i in range(len(labels))])
        plt.xticks(range(len(labels)), labels, rotation=45)
    else:
        pd.Series(y).value_counts().plot(kind='bar')
        plt.xticks(rotation=45)
    
    plt.title(f'{title} - Distribution des Classes')
    plt.xlabel('Classes')
    plt.ylabel('Nombre')
    plt.tight_layout()
    plt.show()

def plot_confusion_matrix(y_true, y_pred, classes, title):
    """Tracer la matrice de confusion am√©lior√©e"""
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(10, 8))
    
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=classes, yticklabels=classes)
    plt.title(f'{title} - Matrice de Confusion')
    plt.xlabel('Pr√©dit')
    plt.ylabel('R√©el')
    plt.tight_layout()
    plt.show()

def plot_metrics_comparison(results_dict, title):
    """Tracer la comparaison des m√©triques entre les mod√®les"""
    models = list(results_dict.keys())
    metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    axes = axes.flatten()
    
    for i, metric in enumerate(metrics):
        if i < len(axes):
            values = [results_dict[model][metric] * 100 for model in models]
            bars = axes[i].bar(models, values)
            axes[i].set_title(f'Comparaison {metric.upper()}')
            axes[i].set_ylabel('Pourcentage (%)')
            axes[i].set_ylim(0, 100)
            
            # Ajouter des √©tiquettes de valeur sur les barres
            for bar, value in zip(bars, values):
                axes[i].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, 
                           f'{value:.1f}%', ha='center', va='bottom')
            
            axes[i].tick_params(axis='x', rotation=45)
    
    # Supprimer le sous-graphique vide
    if len(axes) > len(metrics):
        fig.delaxes(axes[-1])
    
    plt.suptitle(f'{title} - Comparaison des Performances des Mod√®les', fontsize=16)
    plt.tight_layout()
    plt.show()

# ================= R√âGLAGE DES HYPERPARAM√àTRES =================
def tune_hyperparameters(X_train, y_train, clf_name, clf):
    """Effectuer le r√©glage des hyperparam√®tres pour des classificateurs sp√©cifiques"""
    
    param_grids = {
        'RandomForest': {
            'n_estimators': [100, 200],
            'max_depth': [5, 10, None],
            'min_samples_split': [2, 5]
        },
        'GradientBoosting': {
            'n_estimators': [100, 200],
            'learning_rate': [0.05, 0.1, 0.2],
            'max_depth': [3, 6, 9]
        },
        'SVM': {
            'C': [0.1, 1, 10],
            'kernel': ['rbf', 'linear'],
            'gamma': ['scale', 'auto']
        }
    }
    
    if clf_name not in param_grids:
        return clf
    
    print(f"üîß R√©glage des hyperparam√®tres de {clf_name}...")
    
    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)
    grid_search = GridSearchCV(
        clf, param_grids[clf_name], 
        cv=cv, scoring='f1_weighted', 
        n_jobs=-1, verbose=0
    )
    
    grid_search.fit(X_train, y_train)
    print(f"‚úÖ Meilleurs param√®tres pour {clf_name} : {grid_search.best_params_}")
    
    return grid_search.best_estimator_

# ================= BOUCLE D'√âVALUATION PRINCIPALE =================
def evaluate_target_labels():
    """Fonction d'√©valuation principale pour la race et l'√©motion"""
    
    all_results = {}
    
    for label in target_labels:
        print(f"\n{'='*60}")
        print(f"üéØ √âVALUATION DE L'√âTIQUETTE : {label.upper()}")
        print(f"{'='*60}")
        
        # Pr√©parer la variable cible
        y = df[label].dropna()
        X_filtered = X.loc[y.index]
        
        # Encoder les √©tiquettes
        le = LabelEncoder()
        y_encoded = le.fit_transform(y.astype(str))
        
        print(f"üìä Distribution des classes pour {label} :")
        class_counts = pd.Series(y).value_counts()
        for cls, count in class_counts.items():
            percentage = (count / len(y)) * 100
            print(f"   - {cls} : {count} ({percentage:.1f}%)")
        
        # Tracer la distribution des classes
        plot_class_distribution(y, f'Distribution de {label.capitalize()}')
        
        # V√©rifier la stratification
        min_class_count = min(pd.Series(y_encoded).value_counts())
        stratify = y_encoded if min_class_count >= 2 else None
        
        # Diviser les donn√©es
        X_train, X_test, y_train, y_test = train_test_split(
            X_filtered, y_encoded, test_size=0.2, random_state=42, stratify=stratify
        )
        
        print(f"üìà Taille de l'ensemble d'entra√Ænement : {len(X_train)}")
        print(f"üìà Taille de l'ensemble de test : {len(X_test)}")
        
        # Normaliser les caract√©ristiques
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Essayer diff√©rentes strat√©gies d'√©chantillonnage
        best_sampling = None
        best_sampling_score = 0
        
        print(f"\nüîç Test des strat√©gies d'√©chantillonnage...")
        
        for sampling_name, sampler in SAMPLING_STRATEGIES.items():
            try:
                X_train_resampled, y_train_resampled = sampler.fit_resample(X_train_scaled, y_train)
                
                # √âvaluation rapide avec RandomForest
                rf = RandomForestClassifier(n_estimators=50, random_state=42)
                cv_scores = cross_val_score(rf, X_train_resampled, y_train_resampled, 
                                          cv=3, scoring='f1_weighted')
                avg_score = cv_scores.mean()
                
                print(f"   - {sampling_name} : {avg_score:.3f}")
                
                if avg_score > best_sampling_score:
                    best_sampling_score = avg_score
                    best_sampling = sampling_name
                    
            except Exception as e:
                print(f"   - {sampling_name} : √âchec ({str(e)[:50]}...)")
        
        # Appliquer la meilleure strat√©gie d'√©chantillonnage
        if best_sampling:
            print(f"‚úÖ Meilleure strat√©gie d'√©chantillonnage : {best_sampling}")
            sampler = SAMPLING_STRATEGIES[best_sampling]
            X_train_final, y_train_final = sampler.fit_resample(X_train_scaled, y_train)
            print(f"üìä Apr√®s r√©√©chantillonnage : {len(X_train_final)} √©chantillons")
        else:
            X_train_final, y_train_final = X_train_scaled, y_train
            print("‚ö†Ô∏è Aucun √©chantillonnage appliqu√©")
        
        # √âvaluer les classificateurs
        results = {}
        predictions = {}
        
        print(f"\nüöÄ √âvaluation des classificateurs...")
        
        for clf_name, clf in ENHANCED_CLASSIFIERS.items():
            print(f"\n--- {clf_name} ---")
            
            try:
                # R√©glage des hyperparam√®tres pour les mod√®les s√©lectionn√©s
                if clf_name in ['RandomForest', 'GradientBoosting', 'SVM']:
                    tuned_clf = tune_hyperparameters(X_train_final, y_train_final, clf_name, clf)
                else:
                    tuned_clf = clf
                
                # √âvaluer
                metrics, y_pred, y_pred_proba = advanced_evaluate_classifier(
                    X_train_final, X_test_scaled, y_train_final, y_test, tuned_clf, label
                )
                
                results[clf_name] = metrics
                predictions[clf_name] = (y_pred, y_pred_proba)
                
                # Afficher les r√©sultats
                print(f"Pr√©cision :  {metrics['accuracy']*100:.2f}%")
                print(f"Pr√©cision : {metrics['precision']*100:.2f}%")
                print(f"Rappel :    {metrics['recall']*100:.2f}%")
                print(f"F1-Score :  {metrics['f1']*100:.2f}%")
                print(f"F1-Macro :  {metrics['f1_macro']*100:.2f}%")
                print(f"ROC-AUC :   {metrics['roc_auc']*100:.2f}%")
                
                # Validation crois√©e
                cv_scores = cross_val_score(tuned_clf, X_train_final, y_train_final, 
                                          cv=5, scoring='f1_weighted')
                print(f"CV F1 :     {cv_scores.mean()*100:.2f}% ¬± {cv_scores.std()*100:.2f}%")
                
            except Exception as e:
                print(f"‚ùå Erreur avec {clf_name} : {e}")
                results[clf_name] = {
                    'accuracy': 0, 'precision': 0, 'recall': 0, 
                    'f1': 0, 'f1_macro': 0, 'f1_micro': 0, 'roc_auc': 0
                }
        
        # Trouver le meilleur mod√®le
        best_f1 = max(results.values(), key=lambda x: x['f1'])['f1']
        best_models = [name for name, metrics in results.items() if metrics['f1'] == best_f1]
        
        print(f"\nüèÜ MEILLEUR(S) MOD√àLE(S) pour {label} : {', '.join(best_models)}")
        print(f"üéØ Meilleur F1-Score : {best_f1*100:.2f}%")
        
        # Analyse d√©taill√©e pour le meilleur mod√®le
        best_model_name = best_models[0]
        best_y_pred, best_y_pred_proba = predictions[best_model_name]
        
        # Rapport de classification
        print(f"\nüìã Rapport de Classification D√©taill√© pour {best_model_name} :")
        report = classification_report(y_test, best_y_pred, 
                                     target_names=le.classes_, 
                                     zero_division=0)
        print(report)
        
        # Matrice de Confusion
        plot_confusion_matrix(y_test, best_y_pred, le.classes_, 
                            f'{label.capitalize()} - {best_model_name}')
        
        # Graphique de comparaison des m√©triques
        plot_metrics_comparison(results, f'Classification de {label.capitalize()}')
        
        # Stocker les r√©sultats
        all_results[label] = {
            'best_model': best_model_name,
            'best_score': best_f1,
            'all_results': results,
            'class_distribution': class_counts.to_dict(),
            'sampling_strategy': best_sampling
        }
        
        # Importance des caract√©ristiques pour les mod√®les bas√©s sur les arbres
        if best_model_name in ['RandomForest', 'GradientBoosting', 'AdaBoost']:
            best_clf = ENHANCED_CLASSIFIERS[best_model_name]
            if best_model_name in ['RandomForest', 'GradientBoosting', 'SVM']:
                best_clf = tune_hyperparameters(X_train_final, y_train_final, best_model_name, best_clf)
            
            best_clf.fit(X_train_final, y_train_final)
            
            if hasattr(best_clf, 'feature_importances_'):
                feature_importance = pd.DataFrame({
                    'feature': X.columns,
                    'importance': best_clf.feature_importances_
                }).sort_values('importance', ascending=False)
                
                print(f"\nüîç Importance des Caract√©ristiques pour {best_model_name} :")
                for idx, row in feature_importance.head(10).iterrows():
                    print(f"   {row['feature']} : {row['importance']:.4f}")
                
                # Tracer l'importance des caract√©ristiques
                plt.figure(figsize=(12, 8))
                sns.barplot(data=feature_importance.head(15), x='importance', y='feature')
                plt.title(f'{label.capitalize()} - Importance des Caract√©ristiques ({best_model_name})')
                plt.xlabel('Importance')
                plt.tight_layout()
                plt.show()
    
    return all_results

# ================= RAPPORT R√âCAPITULATIF =================
def generate_summary_report(all_results):
    """G√©n√©rer un rapport r√©capitulatif complet"""
    
    print(f"\n{'='*80}")
    print(f"üìä R√âSUM√â D'√âVALUATION COMPLET")
    print(f"{'='*80}")
    
    summary_data = []
    
    for label, results in all_results.items():
        best_model = results['best_model']
        best_score = results['best_score']
        sampling = results['sampling_strategy']
        n_classes = len(results['class_distribution'])
        
        summary_data.append({
            '√âtiquette': label.capitalize(),
            'Meilleur Mod√®le': best_model,
            'F1-Score (%)': f"{best_score*100:.2f}%",
            'Classes': n_classes,
            'Strat√©gie √âchantillonnage': sampling or 'Aucune'
        })
        
        print(f"\nüéØ {label.upper()} :")
        print(f"   - Meilleur Mod√®le : {best_model}")
        print(f"   - F1-Score : {best_score*100:.2f}%")
        print(f"   - Nombre de Classes : {n_classes}")
        print(f"   - Strat√©gie d'√âchantillonnage : {sampling or 'Aucune'}")
        print(f"   - Distribution des Classes : {results['class_distribution']}")
    
    # Cr√©er un DataFrame r√©capitulatif
    summary_df = pd.DataFrame(summary_data)
    print(f"\nüìã TABLEAU R√âCAPITULATIF :")
    print(summary_df.to_string(index=False))
    
    return summary_df

# ================= EX√âCUTER L'√âVALUATION =================
if __name__ == "__main__":
    print("üöÄ D√©marrage du Syst√®me d'√âvaluation Am√©lior√© Race & √âmotion")
    print(f"üìä Taille du dataset : {df.shape}")
    print(f"üéØ √âtiquettes cibles : {target_labels}")
    print(f"üìà Caract√©ristiques : {len(all_features)} caract√©ristiques")
    print(f"ü§ñ Classificateurs : {len(ENHANCED_CLASSIFIERS)} mod√®les")
    print(f"‚öñÔ∏è Strat√©gies d'√©chantillonnage : {len(SAMPLING_STRATEGIES)} m√©thodes")
    
    # Ex√©cuter l'√©valuation
    results = evaluate_target_labels()
    
    # G√©n√©rer le r√©sum√©
    summary = generate_summary_report(results)
    
    print(f"\n‚úÖ √âvaluation termin√©e avec succ√®s !")
    print(f"üí° Consultez les graphiques et rapports g√©n√©r√©s ci-dessus pour des informations d√©taill√©es.")